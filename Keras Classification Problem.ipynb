{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/d4/d895fb7ac1b0828151b829a32cefc8a8b58b4499570520b91af20982b880/PyYAML-3.13-cp35-cp35m-win_amd64.whl (205kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages (from keras)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages (from keras)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages (from keras)\n",
      "Collecting h5py (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/2c/4572e2e495341e667c89b490ad18ea71a5f9e9fafca06109a9c7db22848b/h5py-2.8.0-cp35-cp35m-win_amd64.whl (2.3MB)\n",
      "Installing collected packages: pyyaml, h5py, keras-applications, keras-preprocessing, keras\n",
      "Successfully installed h5py-2.8.0 keras-2.2.4 keras-applications-1.0.6 keras-preprocessing-1.0.5 pyyaml-3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features\n",
    "X = dataset.drop(['RowNumber','CustomerId','Surname','Exited'],axis=1)\n",
    "#labels\n",
    "Y = dataset['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X['Gender'] = labelencoder_X_1.fit_transform(X['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,pd.get_dummies(X['Geography'],prefix=('Georaphy'))],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Geography',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Georaphy_France</th>\n",
       "      <th>Georaphy_Germany</th>\n",
       "      <th>Georaphy_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Georaphy_France  Georaphy_Germany  \\\n",
       "0               1        101348.88                1                 0   \n",
       "1               1        112542.58                0                 0   \n",
       "2               0        113931.57                1                 0   \n",
       "3               0         93826.63                1                 0   \n",
       "4               1         79084.10                0                 0   \n",
       "\n",
       "   Georaphy_Spain  \n",
       "0               0  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 12)\n",
      "(8000,)\n",
      "(2000, 12)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 330us/step - loss: 0.4878 - acc: 0.7956\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 265us/step - loss: 0.4277 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4222 - acc: 0.8095\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4171 - acc: 0.8252\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s 273us/step - loss: 0.4125 - acc: 0.8316\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.4093 - acc: 0.8317\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.4064 - acc: 0.8341\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s 271us/step - loss: 0.4041 - acc: 0.8351\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4025 - acc: 0.8334\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4012 - acc: 0.8370\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 262us/step - loss: 0.3995 - acc: 0.8350\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3996 - acc: 0.8360\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 259us/step - loss: 0.3981 - acc: 0.8356\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 307us/step - loss: 0.3979 - acc: 0.8351\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3973 - acc: 0.8347\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3973 - acc: 0.8342\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 276us/step - loss: 0.3968 - acc: 0.8340\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3965 - acc: 0.8351\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3963 - acc: 0.8364\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 286us/step - loss: 0.3960 - acc: 0.8360\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3957 - acc: 0.8370\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.3958 - acc: 0.8364\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3957 - acc: 0.8347\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s 258us/step - loss: 0.3952 - acc: 0.8356\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s 267us/step - loss: 0.3950 - acc: 0.8345\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.3949 - acc: 0.8355\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 274us/step - loss: 0.3946 - acc: 0.8365\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 258us/step - loss: 0.3943 - acc: 0.8355\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 263us/step - loss: 0.3946 - acc: 0.8352\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.3943 - acc: 0.8365\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3945 - acc: 0.8354\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3939 - acc: 0.8370\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 268us/step - loss: 0.3942 - acc: 0.8365\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3937 - acc: 0.8355\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.3942 - acc: 0.8364\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 268us/step - loss: 0.3938 - acc: 0.8365\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3934 - acc: 0.8367\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 3s 341us/step - loss: 0.3936 - acc: 0.8374\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 290us/step - loss: 0.3939 - acc: 0.8366\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.3936 - acc: 0.8359\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s 249us/step - loss: 0.3934 - acc: 0.8377\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s 255us/step - loss: 0.3932 - acc: 0.8391\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 3s 318us/step - loss: 0.3930 - acc: 0.8380\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 282us/step - loss: 0.3933 - acc: 0.8386\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3931 - acc: 0.8365\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3934 - acc: 0.8370\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s 280us/step - loss: 0.3932 - acc: 0.8360\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3926 - acc: 0.8389\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 248us/step - loss: 0.3932 - acc: 0.8372\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s 290us/step - loss: 0.3927 - acc: 0.8377\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3929 - acc: 0.8384\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3930 - acc: 0.8366\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 261us/step - loss: 0.3931 - acc: 0.8386\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 266us/step - loss: 0.3925 - acc: 0.8376\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.3925 - acc: 0.8391\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 272us/step - loss: 0.3926 - acc: 0.8391\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3927 - acc: 0.8386\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3926 - acc: 0.8372\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3925 - acc: 0.8390\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 2s 275us/step - loss: 0.3924 - acc: 0.8389\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 274us/step - loss: 0.3928 - acc: 0.8396\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.3917 - acc: 0.8387\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s 253us/step - loss: 0.3918 - acc: 0.8412\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.3917 - acc: 0.8392\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3919 - acc: 0.8374\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 280us/step - loss: 0.3913 - acc: 0.8384\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.3914 - acc: 0.8382\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.3908 - acc: 0.8404\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s 280us/step - loss: 0.3887 - acc: 0.8415\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.3849 - acc: 0.8410\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3758 - acc: 0.8484\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s 308us/step - loss: 0.3669 - acc: 0.8521\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3606 - acc: 0.8552\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s 246us/step - loss: 0.3573 - acc: 0.8567\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 278us/step - loss: 0.3553 - acc: 0.8586\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3542 - acc: 0.8574\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s 246us/step - loss: 0.3538 - acc: 0.8579\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 2s 282us/step - loss: 0.3532 - acc: 0.8567\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.3533 - acc: 0.8582\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.3526 - acc: 0.8564\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 288us/step - loss: 0.3523 - acc: 0.8572\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.3516 - acc: 0.8576\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.3518 - acc: 0.8561\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s 264us/step - loss: 0.3519 - acc: 0.8594\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3518 - acc: 0.8576\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.3512 - acc: 0.8585\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 2s 263us/step - loss: 0.3513 - acc: 0.8604\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3510 - acc: 0.8579\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.3513 - acc: 0.8576\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s 267us/step - loss: 0.3509 - acc: 0.8582\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3502 - acc: 0.8596\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3501 - acc: 0.8594\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s 253us/step - loss: 0.3503 - acc: 0.8589\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3500 - acc: 0.8579\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.3499 - acc: 0.8566\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3492 - acc: 0.8590\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 3s 349us/step - loss: 0.3491 - acc: 0.8587\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 2s 299us/step - loss: 0.3496 - acc: 0.8597\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s 281us/step - loss: 0.3491 - acc: 0.8577\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3484 - acc: 0.8577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc6b6be0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=12, units=6, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24218398],\n",
       "       [ 0.3364177 ],\n",
       "       [ 0.1053662 ],\n",
       "       ..., \n",
       "       [ 0.19964315],\n",
       "       [ 0.15621217],\n",
       "       [ 0.22836268]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ..., \n",
       "       [False],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = []\n",
    "for i in y_pred:\n",
    "    if i > 0.5:\n",
    "        yhat.append(1)\n",
    "    else:\n",
    "        yhat.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe885390>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEWCAYAAAAQBZBVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xede69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scikitplot\n",
    "%matplotlib inline\n",
    "scikitplot.metrics.plot_confusion_matrix(y_test,yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "\n",
      "[[1505   90]\n",
      " [ 204  201]]\n",
      "Accuracy :  0.853\n"
     ]
    }
   ],
   "source": [
    "#Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print('Confusion Matrix \\n')\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "print('Accuracy : ',accuracy_score(y_test,yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
